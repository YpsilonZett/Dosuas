\documentclass[a4paper,12pt,ngerman]{scrartcl}

% standard packages
\usepackage{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8x]{inputenc}
\usepackage[a4paper,margin=2.5cm]{geometry}

% additional but often needed packages
\usepackage[colorlinks=true,linkcolor=black,urlcolor=blue,
            citecolor=blue,anchorcolor=blue]{hyperref}
\usepackage{csquotes}

% special packages for this document
\usepackage[official]{eurosym}

% meta information
\title{Dosuas - Die Symphonie des Sehens}
\subtitle{Jugend Forscht 2018}
\author{Jonas Wanke und Yorick Zeschke}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
Dosuas (\textbf{D}evice for \textbf{O}rientation in \textbf{S}pace \textbf{U}sing 
\textbf{A}udio \textbf{S}ignals) ist ein Gerät, welches blinden Menschen ermöglicht
sich mithilfe von Tonsignalen im Raum zu orientieren und Objekte zu erkennen.\par
Das Projekt besteht aus zwei Unterprojekten, die beide bis zum 
Wettbewerb als Prototypen umgesetzt werden sollen. Einmal werden Bilder eines 3D Kamera
mit einem Programm in Töne umgewandelt, die dann mit 3D-Audio Kopfhörern hörbar gemacht
werden. Die andere Idee basiert darauf, so ähnlich wie eine Fledermaus Ultraschall 
Impulse zu senden und deren Reflektionen bzw. Echos hörbar zu machen, sodass man
sich mit Klicklauten orientieren kann. Letzteres basiert auf der Technik der aktiven
menschlichen Echoortung.
\end{abstract}

\tableofcontents

\newpage

\section{Einleitung}

Blinde Menschen haben schon immer Probleme damit, sich im Raum zu orientieren.
Manche von ihnen, zum Beispiel \href{https://en.wikipedia.org/wiki/Daniel_Kish}
{Daniel Kish} benutzen die Technik der \href{https://de.wikipedia.org/wiki/Menschliche_Echoortung}{menschlichen Echoortung}, ein Verfahren, bei dem
man regelmäßig mit dem Mund Klicklaute erzeugt und das Gehör darauf trainiert 
anhand der Reflektionen ein genaues Bild der Umgebung im Kopf zu erzeugen.
Forscher haben herausgefunden, dass sich dabei die Struktur des Gehirns verändert 
und Signale von den Ohren im Sehzentrum verarbeitet werden.
Mit genügend Übung schaffen es Blinde so zu \enquote{sehen} und können Fahrrad 
fahren oder in den Bergen klettern. \par 
Doch nicht jedem Blinden fällt es leicht und nicht jeder hat die Möglichkeit eine
solche Technologie zu erlernen. Außerdem hat auch die menschliche Echoortung ihre
Grenzen und ist ab einem bestimmten Punkt nicht mehr erweiterbar. Hier kommt die 
Technologie ins Spiel. Von Tag zu Tag ergeben sich neue Möglichkeiten mithilfe 
der verschiedensten technischen Hilfsmittel Menschen das Leben zu erleichtern.
Geräte wie 3D-Sensoren oder Kameras können heutzutage schon oft sehr realistische
und detaillierte Bilder aufnehmen, die dem menschlichen Sehen sehr nahe kommen. \par 
Relativ neu ist zum Beispiel die Technologie der 
\href{https://de.wikipedia.org/wiki/Retina-Implantat}{Retina Implantate}, die sich 
momentan aber noch im Anfangsstadium der Entwicklung befinden. Mit ihnen soll es in 
Zukunft möglich sein, dass Blinde wie nicht sehbehinderte Menschen sehen, jedoch
können die Kosten von 75.000 \euro{} aufwärts selten von den Blinden selbst getragen
werden und werden nur manchmal von Krankenkassen übernommen. Auch gibt es zu viele
blinde und sehbehinderte Menschen, als das es möglich wäre jeden mit einem so 
teuren Gerät zu versorgen.\par 
Andere Firmen versuchen das Sehen technisch durch andere Sinne zu ersetzen.
Ein berühmtes Beispiel dafür ist der 
\enquote{\href{https://www.wicab.com/brainport-v100}{BrainPort V100}}, welcher 
Kamerasignale in elektronische Impulse umwandelt, die auf der Zunge spürbar
gemacht werden. Nachteile dieser
Technologie sind vor allem lange Lernprozesse, die nur mit ärztlicher Unterstützung
möglich sind, Probleme bei zu vielen Reizen oder große Ungenauigkeiten.
Beispielsweise kann es passieren, dass ein Blinder beim betrachten des Geschehens auf 
einer großen Straße nichts mehr wahrnimmt, weil die der Tastsinn der zunge
nicht für eine 
solche Reizüberlastung ausgelegt ist. Im Gegensatz dazu wird es vermutlich auch nicht
möglich sein kleine oder komplexere Objekte zu erkennen, weil der Tastsinn der Zunge
dazu wiederum nicht sensibel genug ist. \par
Weil unser Gehirn sehr anpassungsfähig ist und beeindruckende
Leistungen im Finden von Regelmäßigkeiten oder Mustern erbringt, ist der Ansatz
andere Sinne zu verwenden eine vielversprechende Strategie. Darauf setzt auch 
unser Projekt, Dosuas, welches den Hörsinn verwenden möchte um Blinden eine Hilfe
für Orientierung und Erkennung der Umwelt zu geben.
 
\newpage

\section{Echoortungsstrategie}

\subsection{Funktionsweise}

\subsection{Fazit}

\newpage

\section{3D Kamera Strategie}

\subsection{Funktionsweise}

In diesem Teilprojekt werden die Daten einer 3D Kamera als Töne kodiert, die der Träger des Geräts
dann verwenden kann um ein Gefühl für den ihn umgebenden Raum zu bekommen. 

\subsubsection{Verwendete Technologien}

Der wichtigste Teil dieses Projekts ist eine \href{https://de.wikipedia.org/wiki/TOF-Kamera}
{ToF Kamera} (Time of Flight Kamera), die neben normalen Fotos auch sogenannte Tiefenbilder aufnehmen kann.
In einem Tiefenbild bekommt jeder Pixel einen Wert, der die Entfernung zur Kameralinse in mm angibt.
Der von uns verwendete \href{http://www.cube-eye.co.kr/en/#/spec/product_MDC500d.html}{Cube Eye MDC500C}
Sensor hat eine Reichweite von 0.8 bis 5.3 Metern und einer Auflösung von 320x240 Tiefenpixeln. 
Time of Flight Kameras messen die Entfernung mit Infrarotlicht. Deshalb funktioniert der Sensor auch 
im Dunkeln und wird von normalen Lichtreflektionen nicht gestört. Trotzdem hat der Sensor Probleme beim
Erkennen von lichtdurchlässigen oder reflektierenden Objekten (z.B. Glasscheiben oder Spiegel). Für einen
Prototypen ist das aber kein großes Problem. Wir haben diese Kamera ausgewählt, weil sie uns von einem 
Familienmitglied\footnote{Jan Nicklisch, Vater von Yorick Zeschke, arbeitet in der Firma
\href{https://www.dilax.com/de/}{DILAX}, die diese Sensoren für Personenzählsysteme verwendet} 
empfohlen wurde.\par
Einen weiterer wichtiger Teil des Projekts stellen \href{https://en.wikipedia.org/wiki/3D_audio_effect}
{3D-Audio} Kopfhörer dar. Diese können den Eindruck erzeugen, dass sich eine Tonquelle im dreidimensionalen
Raum befindet, bzw. sich bewegt. Dieses Verfahren benutzen wir um dem Träger des Geräts einen Eindruck
davon zu geben in welcher Richtung sich ein Objekt befindet.\par 
Die dritte Komponente ist ein \href{https://de.wikipedia.org/wiki/Raspberry_Pi}{Raspberry Pi}, ein 
Einplatinencomputer auf dem ein Linux Betriebssystem läuft. Dieser ist mit Kopfhörern und ToF Sensor 
verbunden und führt unser Programm aus. Wir verwenden den Raspberry Pi, weil er klein, mobil und 
stromsparend ist.\par 
Zusammen ergeben die drei Bestandteile (und eine mobile Stromquelle) einen Prototypen, den Sie hier 
in der Abbildung sehen können.
\par 
TODO: Bild hier 

\subsubsection{Software}

Das Programm ist in C++ geschrieben, weil die API des ToF Sensors C++ erfordert und C++ eine schnelle
Sprache mit vielen Möglichkeiten ist. Es läuft unter Windows und Linux. Wir verwenden folgende Libraries:
\begin{enumerate}
\item \enquote{MTF API} - eine Schnittstelle mit der man den Cube Eye Sensor ansteuern kann
\item \enquote{\href{http://pointclouds.org/}{PCL}} - eine Bibliothek um mit Punktwolken\footnote{Punktwolken sind (ggf. geordnete) Mengen von Punkten im dreidimensionalen Raum, 
wobei jeder Punkt eine x, y und z Koordinate und einen Index bekommt} zu arbeiten, wir benutzen 
sie für Bildverarbeitung der 3D Daten
\item \enquote{\href{https://www.sfml-dev.org/}{SFML}} - eine einfache Multimedia Bibliothek, 
die wir für das Abspielen von 3D Sounds verwenden 
\end{enumerate} 


\subsection{Praxistest}

\newpage

\section{Diskussion}

\subsection{Entwicklung}

\subsection{Ausblick}

\subsection{Nutzen und Fazit}

\newpage

\section{Anhang}


\end{document}